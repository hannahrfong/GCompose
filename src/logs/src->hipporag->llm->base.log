2025-10-17 23:46:59,065 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:46:59,066 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:46:59,066 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:46:59,322 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:46:59,322 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:46:59,322 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:46:59,499 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:46:59,500 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:46:59,500 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:47:02,683 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:47:02,683 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:47:02,683 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:51:45,673 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:51:45,674 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:51:45,674 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:51:45,880 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:51:45,880 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:51:45,880 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:51:46,170 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:51:46,170 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:51:46,170 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:51:49,108 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:51:49,108 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:51:49,109 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:55:48,667 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:55:48,668 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:55:48,668 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:55:48,920 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:55:48,920 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:55:48,921 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:55:49,539 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:55:49,539 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:55:49,539 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-17 23:55:53,139 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-17 23:55:53,139 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-17 23:55:53,139 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:24:51,525 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:24:51,526 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:24:51,526 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:24:51,801 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:24:51,801 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:24:51,801 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:24:52,398 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:24:52,399 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:24:52,401 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:24:56,277 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:24:56,277 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:24:56,277 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:31:45,947 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:31:45,947 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 15, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:31:45,947 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:31:46,241 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:31:46,241 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 15, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:31:46,242 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:31:46,732 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:31:46,732 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 15, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:31:46,733 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:31:49,263 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:31:49,263 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 15, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:31:49,263 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:32:45,113 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:32:45,113 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 8, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:32:45,113 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:32:45,328 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:32:45,328 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 8, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:32:45,328 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:32:45,497 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:32:45,498 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 8, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:32:45,499 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 00:32:48,607 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 00:32:48,607 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 8, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 00:32:48,607 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 02:00:28,977 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 02:00:28,978 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 02:00:28,978 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 02:00:29,235 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 02:00:29,235 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 02:00:29,235 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 02:00:29,791 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 02:00:29,791 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 02:00:29,792 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 02:00:33,304 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 02:00:33,304 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 02:00:33,304 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 02:15:16,833 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 02:15:16,834 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 02:15:16,834 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 02:17:33,145 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 02:17:33,145 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 02:17:33,146 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 02:19:22,090 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 02:19:22,090 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 02:19:22,090 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 02:19:23,752 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 02:19:23,752 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 02:19:23,752 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 02:21:26,732 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 02:21:26,733 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 02:21:26,733 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 02:24:26,622 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 02:24:26,625 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 02:24:26,625 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 03:44:48,762 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 03:44:48,763 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 03:44:48,763 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 03:47:12,573 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 03:47:12,574 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 03:47:12,574 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 03:47:12,712 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 03:47:12,712 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 03:47:12,712 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 03:47:56,172 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 03:47:56,173 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 03:47:56,173 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 03:48:08,437 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 03:48:08,438 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 03:48:08,438 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 03:48:58,953 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 03:48:58,954 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 03:48:58,954 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 03:49:25,130 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 03:49:25,130 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 03:49:25,131 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 03:50:34,370 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 03:50:34,371 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 03:50:34,371 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
2025-10-18 03:58:44,750 - src.hipporag.llm.base - DEBUG - global config is not given. Using the default ExperimentConfig instance.
2025-10-18 03:58:44,751 - src.hipporag.llm.base - DEBUG - Loading CacheOpenAI with global_config: {'llm_name': 'gpt-4o-mini', 'llm_base_url': None, 'embedding_base_url': None, 'azure_endpoint': None, 'azure_embedding_endpoint': None, 'max_new_tokens': 2048, 'num_gen_choices': 1, 'seed': None, 'temperature': 0, 'response_format': {'type': 'json_object'}, 'max_retry_attempts': 5, 'force_openie_from_scratch': False, 'force_index_from_scratch': False, 'rerank_dspy_file_path': None, 'passage_node_weight': 0.05, 'save_openie': True, 'text_preprocessor_class_name': 'TextPreprocessor', 'preprocess_encoder_name': 'gpt-4o', 'preprocess_chunk_overlap_token_size': 128, 'preprocess_chunk_max_token_size': None, 'preprocess_chunk_func': 'by_token', 'information_extraction_model_name': 'openie_openai_gpt', 'openie_mode': 'online', 'skip_graph': False, 'embedding_model_name': 'nvidia/NV-Embed-v2', 'embedding_batch_size': 16, 'embedding_return_as_normalized': True, 'embedding_max_seq_len': 2048, 'embedding_model_dtype': 'auto', 'synonymy_edge_topk': 2047, 'synonymy_edge_query_batch_size': 1000, 'synonymy_edge_key_batch_size': 10000, 'synonymy_edge_sim_threshold': 0.8, 'is_directed_graph': True, 'linking_top_k': 5, 'retrieval_top_k': 200, 'damping': 0.5, 'max_qa_steps': 1, 'qa_top_k': 5, 'save_dir': 'outputs', 'dataset': None, 'graph_type': 'facts_and_sim_passage_node_unidirectional', 'corpus_len': None}
2025-10-18 03:58:44,751 - src.hipporag.llm.base - DEBUG - Init CacheOpenAI's llm_name with: gpt-4o-mini
